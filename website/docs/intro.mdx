# Optimized Execution for Semantic Operators
[![Discord](https://img.shields.io/discord/1245561987480420445?logo=discord)](https://discord.gg/dN85JJ6jaH)
[![Colab Demo](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1zqOxnh_G6eZ8_xax6PvDr-EjMt7hp4R5?usp=sharing)
[![PyPI](https://img.shields.io/pypi/v/palimpzest)](https://pypi.org/project/palimpzest/)
[![PyPI - Monthly Downloads](https://img.shields.io/pypi/dm/palimpzest?color=teal)](https://pypi.org/project/palimpzest/)
[![GitHub](https://img.shields.io/badge/GitHub-Code-blue?logo=github)](https://github.com/mitdbg/palimpzest)
{/* [![Paper](https://img.shields.io/badge/Paper-arXiv-b31b1b?logo=arxiv)](https://arxiv.org/pdf/2405.14696) */}
{/* [![Video](https://img.shields.io/badge/YouTube-Talk-red?logo=youtube)](https://youtu.be/T8VQfyBiki0?si=eiph57DSEkDNbEIu) */}

Palimpzest (PZ) enables developers to process unstructured data (i.e. documents, images, audio, etc.) using **semantic operators** -- i.e. AI-powered data transformations. PZ programs are *declarative*, which means they express what computation should be performed without specifying exactly *how* to perform it. This allows PZ's optimizer to select the best way to execute each semantic operator in order to minimize cost, minimize latency, or maximize quality, possibly subject to constraints on the other dimensions.

### ‚úâÔ∏è Example: Processing Emails with Semantic Operators
<details>
  <summary>Download Example Dataset</summary>

  The following code snippet sets up PZ and downloads a small datast of emails:

  ```python
  # install palimpzest with pip
  $ pip install palimpzest

  # you can also install palimpzest with uv for a faster install
  # $ uv pip install palimpzest

  # set OpenAI API key
  $ export OPENAI_API_KEY="<your-api-key>"

  # download and extract emails
  $ wget https://palimpzest-workloads.s3.us-east-1.amazonaws.com/emails.zip
  $ unzip emails.zip
  ```
</details>
The following PZ program extracts the subject, sender, and summary of emails which contain first-hand discussion of specific business transactions. The program is written in a high-level declarative language, and PZ automatically optimizes the execution of each semantic operator to maximize output quality:

```python
import palimpzest as pz

# load the emails into a dataset
emails = pz.TextFileDataset(id="enron-emails", path="emails/")

# filter for emails matching natural language criteria
emails = emails.sem_filter(
    'The email refers to one of the following business transactions: "Raptor", "Deathstar", "Chewco", and/or "Fat Boy")',
)
emails = emails.sem_filter(
    "The email contains a first-hand discussion of the business transaction",
)

# extract structured fields for each email
emails = emails.sem_map([
    {"name": "subject", "type": str, "desc": "the subject of the email"},
    {"name": "sender", "type": str, "desc": "the email address of the sender"},
    {"name": "summary", "type": str, "desc": "a brief summary of the email"},
])

# execute the program and print the output
output = emails.run(max_quality=True)

print(output.to_df(cols=["filename", "sender", "subject", "summary"]))
```
The output from this program is shown below:
```
                               filename                                    subject                    sender                                            summary
0  whalley-g-merchant-investments-3.txt         Enron Principal Investments Update   kevin.garland@enron.com  Kevin Garland provides an update on Enron Prin...
1              kaminski-v-inbox-291.txt  RE: Pricing of restriction on Enron stock           baker@enron.com  Ron Baker clarifies to Vince Kaminski that the...
2               delainey-d-sent-683.txt                                 Re: Raptor  david.delainey@enron.com  David Delainey responds about hedging and the ...
3               kaminski-v-inbox-92.txt                                FW: Raptors      j.kaminski@enron.com  Vince Kaminski forwards a previously sent mess...
4               delainey-d-sent-295.txt                                   AIG Fund  david.delainey@enron.com  David Delainey advises colleagues to revise DA...
```
There are a few features of this program which are worth highlighting:

1. The program creates a dataset from the directory of emails and defines a series of ***semantic operations*** on that dataset:
    - `sem_filter()` selects for emails which satisfy each natural language predicate
    - `sem_map()` specifies a set of fields which PZ must compute
2. The user does not specify ***how*** each operation is performed -- they simply declare ***what*** they want PZ to compute
    - This is what makes PZ declarative
3. Internally, PZ's optimizer determines the best way to execute each semantic operator
    - In this example, PZ optimizes for output quality because the user sets `max_quality=True`
3. The `output` is not generated until the call to `emails.run()`
    - i.e. PZ uses [lazy evaluation](https://en.wikipedia.org/wiki/Lazy_evaluation)

### üõ†Ô∏è Naive Optimization
The program above is optimized using **naive prior beliefs** about the quality of different operator implementations for `sem_filter` and `sem_map`. In brief, PZ will implement each `sem_filter` and `sem_map` operation using the available LLM with the highest score on MMLU-Pro. (To minimize cost (or latency) instead, we could call `emails.run(min_cost=True)` (or `min_time=True`) and PZ would use the cheapest (or fastest) available LLM based on per-token costs (or latencies)).

In order to leverage the full power of PZ's optimizer, we need to provide PZ with a `pz.Validator` which can evaluate the quality, cost, and latency of different operator implementations for each semantic operation.

### ‚ú® Optimizing Execution with a Validator
**The real power of Palimpzest** comes from its ability to test multiple implementations of each operator and select the best one based on empirical performance. For example, PZ can select which model to use for each semantic operation -- perhaps opting for a cheaper model that performs well on a given semantic filter or a more expensive model for a challenging semantic map. However, PZ's space of optimizations extends beyond model selection (also called "model routing") to include:
- Model selection
- Ensemble methods (e.g., [Mixture-of-Agents](https://arxiv.org/pdf/2406.04692))
- Refinement strategies (e.g., using a model to propose an answer, a second model to critique the answer, and a third model to refine the answer)
- Context reduction strategies (e.g., using embedding similarity to feed only the top-k most relevant chunks from the input context into the LLM)
- And more!

In order to make use of these advanced optimizations, we need to modify the above program to use a `pz.Validator` with `.optimize_and_run()`:
```python
import palimpzest as pz

...

# execute the program and print the output
validator = pz.Validator(model=pz.Model.GPT_5)
output = emails.optimize_and_run(max_quality=True, validator=validator)

print(output.to_df(cols=["filename", "sender", "subject", "summary"]))
```
The call to `.optimize_and_run()` will cause PZ to first perform an optimization loop where it samples different implementations of each semantic operator and evaluates them using the `pz.Validator` (in this case, GPT-5). After the optimization loop, PZ will select the best implementation of each operator and then execute the optimized program.

The output from this optimized program is shown below:
```
                                filename                                      subject                        sender                                            summary
0                delainey-d-sent-295.txt                                     AIG Fund      david.delainey@enron.com  David Delainey advises toning down claims of s...
1      kaminski-v-all-documents-2352.txt                         RE: Cross-Guarantees           ron.baker@enron.com  Ron Baker sends the latest drafts of three Cro...
2                delainey-d-sent-318.txt  Re: ENA Comp suggestions for Project Raptor      david.delainey@enron.com  David Delainey tells David Oxley to drop the c...
3             giron-d-sent-items-200.txt                           FW: Enron Mentions            c..giron@enron.com  Forwarded email compiling numerous news articl...
4                delainey-d-sent-683.txt                                   Re: Raptor      david.delainey@enron.com  David Delainey discusses hedging and restructu...
5   whalley-g-merchant-investments-3.txt           Enron Principal Investments Update       kevin.garland@enron.com  Update on Enron Principal Investments covering...
6    parks-j-deleted-items-913-short.txt                                   FW: E memo  gregory.schockling@enron.com  Gregory Schockling forwards an email chain reg...
7      kaminski-v-all-documents-2355.txt         Raptor Position Reports for 12/28/00           ron.baker@enron.com  Sends the latest Daily Position Report files f...
8               kaminski-v-inbox-291.txt    RE: Pricing of restriction on Enron stock               baker@enron.com  Ron Baker clarifies confusion about parts of a...
9                kaminski-v-inbox-92.txt                                  FW: Raptors          j.kaminski@enron.com  Vince Kaminski forwards a previously sent mess...
10            beck-s-notes-inbox-166.txt              Re: Enron Raptor I P&L Reversal        shona.wilson@enron.com  Shona Wilson informs recipients that the DPR c...
```
The optimized output contains more relevant emails than the naively optimized program, illustrating the benefit of PZ's optimization framework. In our [user guide on optimization](user-guide/optimization.mdx), we also show how to use labeled data (instead of an LLM) to drive optimization which can further improve performance.

### üìà Declarative Optimization for AI
The core philosophy behind PZ is that programmers should simply specify the high-level logic of their AI programs while offloading much of the performance tuning to a powerful optimizer. Of course, users should still be able to fully control their program and override / assist the optimizer (if needed) to get the best possible performance.

### üöÄ More Semantic Operators
This email processing example only showcases a small set of the semantic operators implemented in PZ. Other operators include:

- `sem_join()` which performs a semantic join between two datasets
- `sem_aggregate()` which performs a semantic aggregation over a dataset
- `sem_flat_map()` which performs semantic map operations producing multiple outputs per input (e.g. extracting all the authors on a single paper)
- `sem_topk()` which takes a vector database and a search string as input and retrieves the top-k relevant entries from the database
- `map()`, `flat_map()`, `filter()`, and `join()` which are the relational equivalents of `sem_map()`, `sem_flat_map()`, `sem_filter()`, and `sem_join()`
- `groupby()`, `count()`, `average()`, `limit()`, and `project()` which mirror their implementations in frameworks like Pandas and Spark.

{/* **[[start of quick editorial note]]**
This^ example is significantly improved from before, but it can be simplified and clarified further:
1. If possible, we should show the (abbreviated) contents of the inputs
2. As discussed offline, the `sem_add_columns()` arguments are very verbose, and it would be nice to support (and show off) syntax like:
    - `emails.sem_add_columns(["sender", "subject"], prompt="Please compute the subject and sent date of the email")`.
**[[end of quick editorial note]]** */}

{/* PZ provides the developer with a high-level interface for composing semantic operators into concise programs. The call to `emails.run()` triggers PZ's optimizer, which automatically selects which LLMs and execution strategies to use for each semantic operation. Users have the ability to fully control the program, and can override and assist the optimizer (if needed) to get the best possible performance. */}

### üôãüèΩ Join our community
We strongly encourage you to join our [Discord server](https://discord.gg/dN85JJ6jaH) where we are happy to help you get started with PZ.

### ‚û°Ô∏è What's Next?
The rest of our Getting Started section will:

1. Help you install PZ
2. Explore more of PZ's features in our [Quick Start Tutorial](getting-started/quickstart.mdx)
3. Give you an overview of our [User Guides](user-guide/overview.mdx) which discuss features of PZ in more depth


{/* Palimpzest is a **cost-based optimizer for AI-powered analytical workloads**. It enables users to express complex AI-powered data queries in a **high-level declarative language**, and it **automatically generates optimized execution plans** that minimize cost, maximize quality, or balance both.

In modern AI applications, executing queries efficiently is a challenge. A single query may require:

* Extracting structured data from unstructured sources (e.g., PDFs, emails, research papers)
* **Choosing between different AI models and inference methods**
* **Managing trade-offs between execution speed, cost, and accuracy**
* **Handling large-scale datasets while minimizing computational overhead**

Traditionally, AI engineers must **manually fine tune** prompts, select models, and optimize inference strategies for each task. This process is not only time consuming but also requires constant updates as models evolve and costs fluctuate.

Palimpzest **solves this problem** by applying **cost-based optimization techniques** similar to a database query optimizer to **AI-powered analytical queries**. Users write **declarative queries**, and Palimpzest:

1. **Analyzes the query structure**  
2. **Explores different execution plans**  
3. **Estimates cost, runtime, and quality**  
4. **Selects the optimal plan** based on user-defined constraints  

üöÄ **Quick Links**:

- **[üìÑ Read the Paper](https://arxiv.org/pdf/2405.14696)**
- **[üìù Read the Blog](https://dsg.csail.mit.edu/projects/palimpzest/)**
- **[‚ñ∂Ô∏è Watch the MIT Video](https://youtu.be/T8VQfyBiki0?si=eiph57DSEkDNbEIu)** 


!!! info "Getting Started I: Install Palimpzest"
    === "PyPi"
        You can find a stable version of the PZ package on PyPI [here](https://pypi.org/project/palimpzest/). To install the package, run:
        ```bash
        $ pip install palimpzest
        ```
    === "Clone Repo"
        Clone the repository and install the package:

        ```bash 
        git clone git@github.com:mitdbg/palimpzest.git
        cd palimpzest
        pip install .
        ```

!!! info "Getting Started II: Demo PZ modules for various tasks"

    === "Quick Start"

        The easiest way to get started with Palimpzest is to run the `quickstart.ipynb` jupyter notebook. We demonstrate the full workflow of working with PZ, including registering a dataset, composing and executing a pipeline, and accessing the results.
        To run the notebook, you can use the following command:
            ```bash
            $ jupyter notebook
            ```
        And then access the notebook from the jupyter interface in your browser at `localhost:8888`.

    === "Even Quicker Start"

        For eager readers, the code in the notebook can be found in the following condensed snippet. However, we do suggest reading the notebook as it contains more insight into each element of the program.
        ```python
        import pandas as pd
        import palimpzest.datamanager.datamanager as pzdm
        from palimpzest.core.data.dataset import Dataset
        from palimpzest.core.lib.fields import Field
        from palimpzest.core.lib.schemas import Schema, TextFile
        from palimpzest.policy import MinCost, MaxQuality
        from palimpzest.query.processor.config import QueryProcessorConfig

        # Dataset registration
        dataset_path = "testdata/enron-tiny"
        dataset_name = "enron-tiny"
        pzdm.DataDirectory().register_local_directory(dataset_path, dataset_name)

        # Dataset loading
        dataset = Dataset(dataset_name, schema=TextFile)

        # Schema definition for the fields we wish to compute
        class Email(Schema):
            """Represents an email, which in practice is usually from a text file"""
            sender = Field(desc="The email address of the sender")
            subject = Field(desc="The subject of the email")
            date = Field(desc="The date the email was sent")

        # Lazy construction of computation to filter for emails about holidays sent in July
        dataset = dataset.convert(Email, desc="An email from the Enron dataset")
        dataset = dataset.filter("The email was sent in July")
        dataset = dataset.filter("The email is about holidays")

        # Executing the compuation
        policy = MinCost()
        config = QueryProcessorConfig(
            policy=policy,
            verbose=True,
            processing_strategy="no_sentinel",
            execution_strategy="sequential",
            optimizer_strategy="pareto",
        )
        results, execution_stats = dataset.run(config)

        # Writing output to disk
        output_df = pd.DataFrame([r.to_dict() for r in results])[["date","sender","subject"]]
        output_df.to_csv("july_holiday_emails.csv")
        ```

    === "Python Demos"

        Below are simple instructions to run PZ on a test data set of enron emails that is included with the system.

        ### Downloading test data
        To run the provided demos, you will need to download the test data. Due to the size of the data, we are unable to include it in the repository. You can download the test data by running the following command from a unix terminal (requires `wget` and `tar`):
        ```
        chmod +x testdata/download-testdata.sh
        ./testdata/download-testdata.sh
        ```
        For convenience, we have also provided a script to register all test data with Palimpzest:
        ```
        chmod +x testdata/register-sources.sh
        ./testdata/register-sources.sh
        ```

        ### Running the Demos
        - Initialize the configuration by running `pz init`.

        - Palimpzest defaults to using OpenAI. You‚Äôll need to export an environment variable `OPENAI_API_KEY`

        - (Skip this step if you ran the `register-sources.sh` script successfully) Add the enron data set with:
        `pz reg --path testdata/enron-tiny --name enron-tiny`

        - Finally, run the simple test program with:
            `python demos/simpleDemo.py --task enron --datasetid enron-eval-tiny --verbose` -->
*/}